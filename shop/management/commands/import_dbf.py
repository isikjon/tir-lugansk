import os
from django.core.management.base import BaseCommand
from django.utils.text import slugify
from django.db import transaction, connection
from shop.models import Category, Brand, Product
from shop.models import ImportFile
from django.utils import timezone
import logging
from django.db.models import Q
from collections import defaultdict
import re

try:
    from dbfread import DBF
except ImportError:
    DBF = None

logger = logging.getLogger(__name__)


class Command(BaseCommand):
    help = '–ò–º–ø–æ—Ä—Ç —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ DBF —Ñ–∞–π–ª–∞ (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö 1–°)'

    def add_arguments(self, parser):
        parser.add_argument('dbf_file', type=str, help='–ü—É—Ç—å –∫ DBF —Ñ–∞–π–ª—É')
        parser.add_argument('--batch-size', type=int, default=5000, help='–†–∞–∑–º–µ—Ä –ø–∞—á–∫–∏ –¥–ª—è bulk_create (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5000)')
        parser.add_argument('--skip-rows', type=int, default=0, help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å N –∑–∞–ø–∏—Å–µ–π (–¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è)')
        parser.add_argument('--encoding', type=str, default='cp1251', help='–ö–æ–¥–∏—Ä–æ–≤–∫–∞ DBF —Ñ–∞–π–ª–∞ (cp1251, utf-8)')
        parser.add_argument('--disable-transactions', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è')
        parser.add_argument('--import-file-id', type=int, default=None, help='ID –∑–∞–ø–∏—Å–∏ ImportFile –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞')
        parser.add_argument('--clear-existing', action='store_true', help='–û—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–≤–∞—Ä—ã –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º')
        parser.add_argument('--test-records', type=int, default=0, help='–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∏–º–ø–æ—Ä—Ç –ø–µ—Ä–≤—ã–º–∏ N –∑–∞–ø–∏—Å—è–º–∏ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)')

    def count_records_in_dbf(self, dbf_file, encoding='cp1251'):
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ DBF —Ñ–∞–π–ª–µ"""
        try:
            table = DBF(dbf_file, encoding=encoding, load=False)
            return len(table)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –∑–∞–ø–∏—Å–µ–π –≤ DBF —Ñ–∞–π–ª–µ: {e}")
            return 0

    def parse_dbf_record(self, record):
        """–ü–∞—Ä—Å–∏—Ç –∑–∞–ø–∏—Å—å –∏–∑ DBF —Ñ–∞–π–ª–∞ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        return {
            'TMP_ID': str(record.get('TMP_ID', '')).strip(),
            'NAME': str(record.get('NAME', '')).strip(),
            'PROPERTY_P': str(record.get('PROPERTY_P', '')).strip(),  # –±—Ä–µ–Ω–¥
            'PROPERTY_T': str(record.get('PROPERTY_T', '')).strip(),  # –∫–∞—Ç–∞–ª–æ–∂–Ω—ã–π –Ω–æ–º–µ—Ä
            'PROPERTY_A': str(record.get('PROPERTY_A', '')).strip(),  # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä
            'PROPERTY_M': str(record.get('PROPERTY_M', '')).strip(),  # –ø—Ä–∏–º–µ–Ω—è–µ–º–æ—Å—Ç—å
            'PROPERTY_C': str(record.get('PROPERTY_C', '')).strip(),  # –∫—Ä–æ—Å—Å-–∫–æ–¥
            'SECTION_ID': str(record.get('SECTION_ID', '')).strip(),  # –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        }

    def handle(self, *args, **options):
        if not DBF:
            error_msg = '–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ dbfread –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞! –í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install dbfread'
            self.stdout.write(self.style.ERROR(error_msg))
            logger.error(error_msg)
            return

        dbf_file = options['dbf_file']
        batch_size = options['batch_size']
        skip_rows = options['skip_rows']
        encoding = options['encoding']
        disable_transactions = options['disable_transactions']
        import_file_id = options.get('import_file_id')
        clear_existing = options.get('clear_existing', False)
        test_records = options.get('test_records', 0)
        import_file = None
        
        self.stdout.write(f'üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∏–º–ø–æ—Ä—Ç DBF —Ñ–∞–π–ª–∞: {dbf_file}')
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∏–º–ø–æ—Ä—Ç DBF —Ñ–∞–π–ª–∞: {dbf_file}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ImportFile –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if import_file_id:
            import_file = ImportFile.objects.filter(id=import_file_id).first()
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(
                    status='processing',
                    error_log='',
                    processed=False,
                    current_row=0,
                    processed_rows=0,
                    created_products=0,
                    updated_products=0,
                    error_count=0,
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(dbf_file):
            error_msg = f'DBF —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {dbf_file}'
            self.stdout.write(self.style.ERROR(error_msg))
            logger.error(error_msg)
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(status='failed', error_log=error_msg)
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not dbf_file.lower().endswith('.dbf'):
            error_msg = f'–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .dbf: {dbf_file}'
            self.stdout.write(self.style.ERROR(error_msg))
            logger.error(error_msg)
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(status='failed', error_log=error_msg)
            return

        # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–≤–∞—Ä—ã –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–ª–∞–≥
        if clear_existing:
            self.stdout.write('üóëÔ∏è –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–≤–∞—Ä—ã...')
            deleted_count = Product.objects.count()
            Product.objects.all().delete()
            self.stdout.write(f'‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤')
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤")
            
            # –û—á–∏—â–∞–µ–º –∫—ç—à–∏
            existing_tmp_ids = set()
            existing_codes = set()
            all_categories = {}
            all_brands = {}
        else:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            self.stdout.write('üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å...')
            
            existing_tmp_ids = set(Product.objects.values_list('tmp_id', flat=True))
            existing_codes = set(Product.objects.values_list('slug', flat=True))
            all_categories = {cat.slug: cat for cat in Category.objects.all()}
            all_brands = {brand.slug: brand for brand in Brand.objects.all()}
            
            self.stdout.write(f'üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ:')
            self.stdout.write(f'   ‚Ä¢ {len(existing_tmp_ids)} —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ TMP_ID')
            self.stdout.write(f'   ‚Ä¢ {len(existing_codes)} —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ slug')
            self.stdout.write(f'   ‚Ä¢ {len(all_categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π')
            self.stdout.write(f'   ‚Ä¢ {len(all_brands)} –±—Ä–µ–Ω–¥–æ–≤')
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: —Ç–æ–≤–∞—Ä—ã={len(existing_tmp_ids)}, –∫–∞—Ç–µ–≥–æ—Ä–∏–∏={len(all_categories)}, –±—Ä–µ–Ω–¥—ã={len(all_brands)}")

        # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–∫—Ä—ã—Ç—å DBF —Ñ–∞–π–ª
        try:
            table = DBF(dbf_file, encoding=encoding)
            total_records = len(table)
            self.stdout.write(f'üìã –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ DBF —Ñ–∞–π–ª–µ: {total_records}')
            logger.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ DBF —Ñ–∞–π–ª–µ: {total_records}")
            
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(total_rows=total_records)
                
        except Exception as e:
            error_msg = f'–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è DBF —Ñ–∞–π–ª–∞: {str(e)}'
            self.stdout.write(self.style.ERROR(error_msg))
            logger.error(error_msg)
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(status='failed', error_log=error_msg)
            return

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        categories_cache = {}
        brands_cache = {}
        stats = defaultdict(int)
        processed_records = 0
        errors = 0
        products_batch = []

        # –í—ã–≤–æ–¥–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        try:
            first_record = next(iter(table))
            self.stdout.write('üîç –°—Ç—Ä—É–∫—Ç—É—Ä–∞ DBF —Ñ–∞–π–ª–∞:')
            for key, value in first_record.items():
                self.stdout.write(f'   {key}: {value} ({type(value).__name__})')
            logger.info(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ DBF: {list(first_record.keys())}")
        except Exception as e:
            self.stdout.write(f'‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å: {e}')

        try:
            if not disable_transactions:
                connection.autocommit = False

            # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–µ–π
            for record_num, record in enumerate(table, start=1):
                try:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
                    if record_num <= skip_rows:
                        continue
                        
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    if test_records > 0 and record_num > test_records:
                        self.stdout.write(f'üî¨ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {test_records}')
                        break

                    # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –∏–∑ DBF –∑–∞–ø–∏—Å–∏
                    data = self.parse_dbf_record(record)
                    
                    tmp_id = data.get('TMP_ID', '').strip()
                    name = data.get('NAME', '').strip()
                    producer = data.get('PROPERTY_P', '').strip()  # –±—Ä–µ–Ω–¥
                    catalog_number = data.get('PROPERTY_T', '').strip()  # –∫–∞—Ç–∞–ª–æ–∂–Ω—ã–π –Ω–æ–º–µ—Ä
                    artikyl_number = data.get('PROPERTY_A', '').strip()  # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä
                    applicability = data.get('PROPERTY_M', '').strip()  # –ø—Ä–∏–º–µ–Ω—è–µ–º–æ—Å—Ç—å
                    cross_number = data.get('PROPERTY_C', '').strip()  # –∫—Ä–æ—Å—Å-–∫–æ–¥
                    section_id = data.get('SECTION_ID', '').strip()  # –∫–∞—Ç–µ–≥–æ—Ä–∏—è

                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    if record_num <= 5:
                        logger.info(f"–ó–∞–ø–∏—Å—å {record_num}: TMP_ID={tmp_id}, NAME={name}, PRODUCER={producer}, SECTION={section_id}")
                        self.stdout.write(f"üîç –ó–∞–ø–∏—Å—å {record_num}: TMP_ID={tmp_id}, NAME={name[:30]}...")

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—É—Å—Ç—ã–µ –ø–æ–ª—è
                    if not tmp_id:
                        tmp_id = f"auto-{record_num}"
                        logger.warning(f"–ó–∞–ø–∏—Å—å {record_num}: –ü—É—Å—Ç–æ–π TMP_ID, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω '{tmp_id}'")
                        
                    if not name:
                        name = "–¢–æ–≤–∞—Ä –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
                        logger.warning(f"–ó–∞–ø–∏—Å—å {record_num}: –ü—É—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ '{name}'")

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ TMP_ID
                    original_tmp_id = tmp_id
                    counter = 1
                    while tmp_id in existing_tmp_ids:
                        tmp_id = f"{original_tmp_id}-dup{counter}"
                        counter += 1
                        
                    if tmp_id != original_tmp_id:
                        logger.warning(f"–ó–∞–ø–∏—Å—å {record_num}: –î—É–±–ª–∏–∫–∞—Ç TMP_ID '{original_tmp_id}', –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ '{tmp_id}'")

                    # –°–æ–∑–¥–∞–µ–º/–ø–æ–ª—É—á–∞–µ–º –±—Ä–µ–Ω–¥
                    brand = None
                    if producer:
                        brand_slug = slugify(producer)
                        if brand_slug in all_brands:
                            brand = all_brands[brand_slug]
                        elif brand_slug not in brands_cache:
                            brand, created = Brand.objects.get_or_create(
                                slug=brand_slug,
                                defaults={
                                    'name': producer,
                                    'description': f'–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã–π –±—Ä–µ–Ω–¥ –¥–ª—è {producer}'
                                }
                            )
                            all_brands[brand_slug] = brand
                            brands_cache[brand_slug] = brand
                            if created:
                                stats['new_brands'] += 1
                                self.stdout.write(f'üè≠ –°–æ–∑–¥–∞–Ω –±—Ä–µ–Ω–¥: {brand.name}')
                                logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –±—Ä–µ–Ω–¥: {brand.name}")
                        else:
                            brand = brands_cache[brand_slug]

                    # –°–æ–∑–¥–∞–µ–º/–ø–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                    category = None
                    if section_id:
                        category_slug = slugify(f"category-{section_id}")
                        if category_slug in all_categories:
                            category = all_categories[category_slug]
                        elif category_slug not in categories_cache:
                            category, created = Category.objects.get_or_create(
                                slug=category_slug,
                                defaults={
                                    'name': f'–ö–∞—Ç–µ–≥–æ—Ä–∏—è {section_id}',
                                    'description': f'–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –¥–ª—è {section_id}'
                                }
                            )
                            all_categories[category_slug] = category
                            categories_cache[category_slug] = category
                            if created:
                                stats['new_categories'] += 1
                                self.stdout.write(f'üìÅ –°–æ–∑–¥–∞–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category.name}')
                                logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category.name}")
                        else:
                            category = categories_cache[category_slug]

                    # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π slug –¥–ª—è —Ç–æ–≤–∞—Ä–∞
                    clean_name = slugify(name)[:30] if name else 'product'
                    clean_tmp_id = re.sub(r'[^a-zA-Z0-9]', '', tmp_id) if tmp_id else 'unknown'
                    base_slug = f"{clean_name}-{clean_tmp_id}"
                    slug = slugify(base_slug)
                    
                    if not slug:
                        slug = f"product-{clean_tmp_id}"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å slug
                    counter = 1
                    original_slug = slug
                    while slug in existing_codes:
                        slug = f"{original_slug}-{counter}"
                        counter += 1
                    
                    existing_codes.add(slug)
                    existing_tmp_ids.add(tmp_id)

                    # –°–æ–∑–¥–∞–µ–º —Ç–æ–≤–∞—Ä
                    product = Product(
                        tmp_id=tmp_id,
                        name=name[:200], 
                        slug=slug,
                        category=category,
                        brand=brand,
                        code=tmp_id,
                        catalog_number=catalog_number[:50] if catalog_number else tmp_id,
                        cross_number=cross_number[:100] if cross_number else '',
                        artikyl_number=artikyl_number[:100] if artikyl_number else '',
                        applicability=applicability[:500] if applicability else '–£—Ç–æ—á–Ω—è–π—Ç–µ',
                        price=0,  # –¶–µ–Ω–∞ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
                        in_stock=True,
                        is_new=True,
                    )

                    products_batch.append(product)
                    stats['new_products'] += 1
                    processed_records += 1

                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    if processed_records % 1000 == 0:
                        progress = (processed_records / total_records) * 100
                        self.stdout.write(f'‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({processed_records}/{total_records}) | –°–æ–∑–¥–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {stats["new_products"]}')
                        logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%, —Å–æ–∑–¥–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {stats['new_products']}")
                        
                        if import_file:
                            ImportFile.objects.filter(id=import_file.id).update(
                                current_row=processed_records,
                                processed_rows=processed_records,
                                created_products=stats['new_products'],
                                error_count=errors,
                            )

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—á–∫—É —Ç–æ–≤–∞—Ä–æ–≤
                    if len(products_batch) >= batch_size:
                        self._save_products_batch(products_batch)
                        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–∞—á–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤: {len(products_batch)}")
                        products_batch = []
                        
                        if import_file:
                            ImportFile.objects.filter(id=import_file.id).update(
                                processed_rows=processed_records,
                                created_products=stats['new_products']
                            )

                except Exception as e:
                    errors += 1
                    if errors <= 10:
                        error_msg = f'–û—à–∏–±–∫–∞ –≤ –∑–∞–ø–∏—Å–∏ {record_num}: {str(e)}'
                        self.stdout.write(self.style.ERROR(error_msg))
                        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∑–∞–ø–∏—Å–∏ {record_num}: {str(e)}")
                    
                    if import_file:
                        ImportFile.objects.filter(id=import_file.id).update(error_count=errors)
                    continue

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ç–æ–≤–∞—Ä—ã
            if products_batch:
                self._save_products_batch(products_batch)
                logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø–∞—á–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤: {len(products_batch)}")

            if not disable_transactions:
                connection.autocommit = True

            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            final_stats = (
                f'\nüéâ –ò–º–ø–æ—Ä—Ç DBF –∑–∞–≤–µ—Ä—à–µ–Ω!\n'
                f'üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {processed_records}\n'
                f'üìÅ –°–æ–∑–¥–∞–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {stats["new_categories"]}\n'
                f'üè≠ –°–æ–∑–¥–∞–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {stats["new_brands"]}\n'
                f'üì¶ –°–æ–∑–¥–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {stats["new_products"]}\n'
                f'‚ö†Ô∏è –û—à–∏–±–æ–∫: {errors}'
            )

            # –õ–æ–≥–∏—Ä—É–µ–º –±–µ–∑ —ç–º–æ–¥–∑–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
            final_stats_log = (
                f'–ò–º–ø–æ—Ä—Ç DBF –∑–∞–≤–µ—Ä—à–µ–Ω! '
                f'–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {processed_records}, '
                f'–°–æ–∑–¥–∞–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {stats["new_categories"]}, '
                f'–°–æ–∑–¥–∞–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {stats["new_brands"]}, '
                f'–°–æ–∑–¥–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {stats["new_products"]}, '
                f'–û—à–∏–±–æ–∫: {errors}'
            )

            self.stdout.write(self.style.SUCCESS(final_stats))
            logger.info(final_stats_log)
            
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(
                    processed=True,
                    processed_at=timezone.now(),
                    status='completed',
                    current_row=processed_records,
                    processed_rows=processed_records,
                    created_products=stats['new_products'],
                    error_count=errors,
                )

        except Exception as e:
            error_msg = f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ DBF: {str(e)}'
            self.stdout.write(self.style.ERROR(error_msg))
            logger.error(error_msg)
            
            if not disable_transactions:
                connection.autocommit = True
                
            if import_file:
                ImportFile.objects.filter(id=import_file.id).update(status='failed', error_log=error_msg)

    def _save_products_batch(self, products_batch):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—á–∫—É —Ç–æ–≤–∞—Ä–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—á–∫–∏ –∏–∑ {len(products_batch)} —Ç–æ–≤–∞—Ä–æ–≤")
            
            created_products = Product.objects.bulk_create(products_batch, ignore_conflicts=True)
            actual_count = len(created_products)
            
            logger.info(f"–§–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {actual_count} –∏–∑ {len(products_batch)}")
            
            if actual_count < len(products_batch):
                logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑-–∑–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤: {len(products_batch) - actual_count}")
            
            self.stdout.write(f'üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–∞—á–∫–∞ –∏–∑ {len(products_batch)} —Ç–æ–≤–∞—Ä–æ–≤')
            
        except Exception as e:
            error_msg = f'–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤: {str(e)}'
            self.stdout.write(self.style.ERROR(error_msg))
            logger.error(error_msg)
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ –æ–¥–Ω–æ–º—É —Ç–æ–≤–∞—Ä—É
            for product in products_batch:
                try:
                    product.save()
                    logger.info(f"–¢–æ–≤–∞—Ä {product.tmp_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø–æ –æ–¥–Ω–æ–º—É")
                except Exception as single_error:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–≤–∞—Ä {product.tmp_id}: {str(single_error)}")
